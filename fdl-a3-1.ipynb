{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport numpy as np\nimport pandas as pd\nimport torch\nimport random\nimport wandb\nimport torch.nn as nn","metadata":{"id":"U2XJa6S3Yk4B","execution":{"iopub.status.busy":"2023-05-03T22:03:10.082936Z","iopub.execute_input":"2023-05-03T22:03:10.083690Z","iopub.status.idle":"2023-05-03T22:03:16.966136Z","shell.execute_reply.started":"2023-05-03T22:03:10.083660Z","shell.execute_reply":"2023-05-03T22:03:16.965309Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device_name = torch.device(\"cuda\")\nelse:\n    device_name = torch.device('cpu')\nprint(\"Using {}.\".format(device_name))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZG0Efld9B2w","outputId":"66a2b409-d1dc-4fdf-fd62-5692a5c66f9b","execution":{"iopub.status.busy":"2023-05-03T22:03:16.968009Z","iopub.execute_input":"2023-05-03T22:03:16.968382Z","iopub.status.idle":"2023-05-03T22:03:17.031107Z","shell.execute_reply.started":"2023-05-03T22:03:16.968351Z","shell.execute_reply":"2023-05-03T22:03:17.030144Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using cuda.\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocessingData(df):\n    eng_maxlen = len(max(df['eng'], key=len))\n    hin_maxlen = len(max(df['hin'], key=len))\n    max_len = max(eng_maxlen, hin_maxlen)\n    eng_words = df['eng'].copy()\n    for i in range(len(eng_words)):\n      l = len(eng_words[i])\n      eng_words[i] = eng_words[i] + \"*\"*(max_len - l + 3)\n    hin_words = df['hin'].copy()\n    for i in range(len(hin_words)):\n      l = len(hin_words[i])\n      hin_words[i] = \"#\" + hin_words[i] + \"*\"*(max_len - l + 2)\n    unique_eng_letters = set(''.join(eng_words))\n    unique_hin_letters = set(''.join(hin_words))\n    int_to_eng = dict(enumerate(unique_eng_letters))\n    eng_to_int = {char: ind for ind, char in int_to_eng.items()}\n\n    int_to_hin = dict(enumerate(unique_hin_letters))\n    hin_to_int = {char: ind for ind, char in int_to_hin.items()}\n    \n    index_eng_words = []\n    for eng_word in eng_words:\n      index_eng_word = [eng_to_int[i] for i in eng_word]\n      index_eng_words.append(index_eng_word)\n    index_hin_words = []\n    for hin_word in hin_words:\n      index_hin_word = [hin_to_int[i] for i in hin_word]\n      index_hin_words.append(index_hin_word)\n    tensor_eng = torch.tensor(index_eng_words).to(device_name)\n    tensor_hin = torch.tensor(index_hin_words).to(device_name)\n    return tensor_eng, tensor_hin, int_to_eng, int_to_hin, unique_eng_letters, unique_hin_letters\n","metadata":{"execution":{"iopub.status.busy":"2023-05-03T22:03:17.032437Z","iopub.execute_input":"2023-05-03T22:03:17.033323Z","iopub.status.idle":"2023-05-03T22:03:17.044130Z","shell.execute_reply.started":"2023-05-03T22:03:17.033288Z","shell.execute_reply":"2023-05-03T22:03:17.043151Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class GRU_Encoder(nn.Module):\n  def __init__(self, input_size, hid_size, num_of_enc_layers, emb_size, batch_size, dropout, bi_direct):\n    super(GRU_Encoder, self).__init__()\n    self.input_size = input_size\n    self.hid_size = hid_size\n    self.num_of_enc_layers = num_of_enc_layers\n    self.emb_size = emb_size\n    self.batch_size = batch_size\n    self.bi_direct = bi_direct\n    self.dropout = dropout\n    self.embedding = nn.Embedding(input_size, emb_size)\n    # print(\"IS:{} ES:{}\".format(input_size, emb_size))\n    self.gru = nn.GRU(emb_size, hid_size, num_of_enc_layers, bidirectional = bi_direct, dropout = dropout)\n\n  def forward(self, input_data, hidden):\n    input_data = input_data.T\n    # print(input_data.shape)\n    embed = self.embedding(input_data).to(device_name)\n    # print(embed.shape,hidden.shape)\n    # embed = embed.view(-1, self.batch_size, self.hid_size)\n    output, hidden = self.gru(embed, hidden)\n    # if(self.bi_direct):\n    #   print(\"bir\\n\")\n    #   hidden = hidden.resize(2, self.num_of_enc_layers, self.batch_size, self.hid_size)\n    #   print(hidden.shape)\n    #   hidden = torch.add(hidden[0], hidden[1])/2\n    #   print(hidden.shape)\n    return output, hidden\n  \n  def initialiseHidden(self):\n    if(self.bi_direct):\n      return torch.zeros(2*self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n    else:\n      return torch.zeros(self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n  ","metadata":{"id":"S4q529z-FjCx","execution":{"iopub.status.busy":"2023-05-03T22:03:17.047808Z","iopub.execute_input":"2023-05-03T22:03:17.048326Z","iopub.status.idle":"2023-05-03T22:03:17.057729Z","shell.execute_reply.started":"2023-05-03T22:03:17.048303Z","shell.execute_reply":"2023-05-03T22:03:17.056969Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class GRU_Decoder(nn.Module):\n  def __init__(self, op_size, num_of_dec_layers, hid_size, batch_size, emb_size, dropout, bi_direct):\n    super(GRU_Decoder, self).__init__()\n    self.op_size = op_size\n    self.hid_size = hid_size\n    self.num_of_dec_layers = num_of_dec_layers\n    self.emb_size = emb_size\n    self.batch_size = batch_size\n    self.bi_direct = bi_direct\n    self.embedding = nn.Embedding(op_size, emb_size)\n    self.op = nn.Linear(2*hid_size, op_size) if (bi_direct) else nn.Linear(hid_size, op_size)\n    self.softmax = nn.LogSoftmax(dim = 2)\n    self.gru = nn.GRU(emb_size, hid_size, num_of_dec_layers, bidirectional = bi_direct, dropout = dropout)\n\n  def forward(self, input_data, hidden):\n    # print(input_data)\n    embed = self.embedding(input_data)\n    embed = embed.view(-1, self.batch_size, self.emb_size)\n#     print(hidden.shape)\n    out, hidden = self.gru(embed, hidden)\n    # print(out.shape)\n    temp = self.op(out)\n    out = self.softmax(temp)\n    return out, hidden","metadata":{"id":"uDr5Mjb6Fi0a","execution":{"iopub.status.busy":"2023-05-03T22:03:17.060195Z","iopub.execute_input":"2023-05-03T22:03:17.061098Z","iopub.status.idle":"2023-05-03T22:03:17.072226Z","shell.execute_reply.started":"2023-05-03T22:03:17.061068Z","shell.execute_reply":"2023-05-03T22:03:17.071585Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type):\n  teacher_forcing = 0.5\n  loss = 0\n  total = 0\n  c = 0\n  \n  for b in range(0, len(input_data), batch_size):\n    \n    x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n    temp = 0\n    enc_optimizer.zero_grad()\n    dec_optimizer.zero_grad()\n    # x = x.T\n    # y = y.T\n    if(cell_type == 'GRU'):\n      enc_hidden = encoder.initialiseHidden()\n      enc_output, enc_hidden = encoder(x, enc_hidden)\n#       print(\"AFT_Encoder Hidden : {}\".format(enc_hidden.shape))\n#       if(num_of_dec_layers > num_of_enc_layers):\n# #         print(\"1\")\n#         num = num_of_dec_layers-2\n#         dec_hidden = enc_hidden\n#         while(num != num_of_enc_layers):\n#           dec_hidden = torch.cat([dec_hidden, enc_hidden[-1].unsqueeze(0)], dim = 0)\n#           num -= 1\n#       elif(num_of_dec_layers < num_of_enc_layers):\n# #         print(\"2\")\n#         dec_hidden = enc_hidden[-num_of_dec_layers:]\n#       else:\n# #         print(\"3\")\n#         dec_hidden = enc_hidden\n      dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n      if bi_direct:\n        dec_hidden = dec_hidden.repeat(2,1,1)\n      y = y.T\n      dec_input = y[0]\n#       print(\"AFT_Decoder Hidden : {}\".format(dec_hidden.shape))\n      condition = False if random.random() > teacher_forcing else True\n      if(condition):\n        for i in range(len(y)):\n          dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n          temp = loss_fn(torch.squeeze(dec_output), y[i])\n          loss += temp.item()\n          c += 1\n          dec_input = y[i]\n      else:\n        for i in range(len(y)):\n          dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n          prob, idx = dec_output.topk(1)\n          temp = loss_fn(torch.squeeze(dec_output), y[i])\n          loss += temp.item()\n          c += 1\n#           print(idx)\n          dec_input = idx\n    temp.backward()\n    enc_optimizer.step()\n    dec_optimizer.step()\n    print(\"\\tRunning loss\",loss/c)\n#     total += 1\n#     loss += (temp/c)\n    \n  # print(len(target_data))\n  return loss/c, encoder, decoder\n\n","metadata":{"id":"KToV_mC2WtPI","execution":{"iopub.status.busy":"2023-05-03T22:15:47.696580Z","iopub.execute_input":"2023-05-03T22:15:47.697244Z","iopub.status.idle":"2023-05-03T22:15:47.709001Z","shell.execute_reply.started":"2023-05-03T22:15:47.697210Z","shell.execute_reply":"2023-05-03T22:15:47.706172Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"def eval(input_data, target_data, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, cell_type):\n  out = []\n  for b in range(0, len(input_data), batch_size):\n    x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n    encoder.eval()\n    decoder.eval()\n    predicted_data = list()\n    # x = x.T\n    # y = y.T\n    if(cell_type == 'GRU'):\n      enc_hidden = encoder.initialiseHidden()\n      enc_output, enc_hidden = encoder(x, enc_hidden)\n    \n      \n#       if(num_of_dec_layers > num_of_enc_layers):\n#         num = num_of_dec_layers\n#         dec_hidden = enc_hidden\n#         while(num != num_of_enc_layers):\n#           dec_hidden = torch.cat([dec_hidden, enc_hidden[-1].unsqueeze(0)], dim = 0)\n#           num -= 1\n#       elif(num_of_dec_layers < num_of_enc_layers):\n#         dec_hidden = enc_hidden[-num_of_dec_layers:]\n#       else:\n#         dec_hidden = enc_hidden\n      y = y.T\n      \n      dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers,1,1)\n      dec_input = y[0]\n\n      for i in range(len(y)):\n        dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n        prob, idx = dec_output.topk(1)\n        idx = idx.squeeze()\n        dec_input = idx\n        predicted_data.append(idx.tolist())\n      out.append(predicted_data)\n  return out\n","metadata":{"id":"tosOCKpmU49G","execution":{"iopub.status.busy":"2023-05-03T22:15:47.892551Z","iopub.execute_input":"2023-05-03T22:15:47.892872Z","iopub.status.idle":"2023-05-03T22:15:47.899669Z","shell.execute_reply.started":"2023-05-03T22:15:47.892846Z","shell.execute_reply":"2023-05-03T22:15:47.898761Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"def training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, enc_dropout, dec_dropout, beam_size):\n  learning_rate = 0.001\n  if(cell_type == \"GRU\"):\n    encoder = GRU_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n    decoder = GRU_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n  \n  enc_optimizer = torch.optim.Adam(encoder.parameters(), learning_rate)\n  dec_optimizer = torch.optim.Adam(decoder.parameters(), learning_rate)\n  loss_fn = nn.CrossEntropyLoss(reduction = 'sum')\n  encoder.train()\n  decoder.train()\n  loss_list = []\n  for i in range(epochs):\n    loss, encoder, decoder = train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\n    loss_list.append(loss/51200)\n    print(\"Epoch : {} \\tLoss : {}\".format(i, loss))\n\n  return encoder, decoder, num_of_enc_layers, num_of_dec_layers\n","metadata":{"id":"ifkAGoezFiwH","execution":{"iopub.status.busy":"2023-05-03T22:15:48.072162Z","iopub.execute_input":"2023-05-03T22:15:48.072498Z","iopub.status.idle":"2023-05-03T22:15:48.079864Z","shell.execute_reply.started":"2023-05-03T22:15:48.072471Z","shell.execute_reply":"2023-05-03T22:15:48.078966Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"def calculateAccuracy(y_pred, y_true):\n  cnt = 0\n  for i,j in zip(y_pred, y_true):\n    cor = torch.eq(i, j)\n    if(torch.mean(cor.float()).item() == 1.0):\n      cnt += 1\n  return cnt / len(y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T22:15:48.439694Z","iopub.execute_input":"2023-05-03T22:15:48.440052Z","iopub.status.idle":"2023-05-03T22:15:48.445663Z","shell.execute_reply.started":"2023-05-03T22:15:48.440020Z","shell.execute_reply":"2023-05-03T22:15:48.444696Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/fdl-a3/hin_train.csv', names=['eng','hin'])\ntensor_eng, tensor_hin, int_to_eng, int_to_hin, unique_eng_letters, unique_hin_letters = preprocessingData(df)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T22:15:48.601993Z","iopub.execute_input":"2023-05-03T22:15:48.602743Z","iopub.status.idle":"2023-05-03T22:15:50.969512Z","shell.execute_reply.started":"2023-05-03T22:15:48.602699Z","shell.execute_reply":"2023-05-03T22:15:50.968587Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"input_data = tensor_eng\ninput_size = len(unique_eng_letters)\ntarget_data = tensor_hin\ntarget_size = len(unique_hin_letters) \nmax_input_size = tensor_eng.shape[1] \nepochs = 7\nbatch_size = 64 \nemb_size = 256 \nnum_of_enc_layers = 2\nnum_of_dec_layers = 3\nhid_size = 256\ncell_type = \"GRU\" \nbi_direct = True \nenc_dropout = 0.3\ndec_dropout = 0.3 \nbeam_size = 1","metadata":{"execution":{"iopub.status.busy":"2023-05-03T22:15:50.973512Z","iopub.execute_input":"2023-05-03T22:15:50.973785Z","iopub.status.idle":"2023-05-03T22:15:50.981357Z","shell.execute_reply.started":"2023-05-03T22:15:50.973763Z","shell.execute_reply":"2023-05-03T22:15:50.980512Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"encoder, decoder, num_of_enc_layers, num_of_dec_layers = training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, enc_dropout, dec_dropout, beam_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Us7xCAvmwhbE","outputId":"2a475a4b-106d-4958-f7bc-f1df04d947cf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_pred = eval(tensor_eng, tensor_hin, encoder, decoder, num_of_enc_layers, num_of_dec_layers, 64, \"GRU\")","metadata":{"id":"9kejVozOEl_o","execution":{"iopub.status.busy":"2023-05-03T22:04:26.808090Z","iopub.status.idle":"2023-05-03T22:04:26.809056Z","shell.execute_reply.started":"2023-05-03T22:04:26.808777Z","shell.execute_reply":"2023-05-03T22:04:26.808808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = []\nten_pred = torch.tensor(trained_pred)\nfor i in range(len(trained_pred)):\n    temp = ten_pred[i].T\n    out.extend(temp)\nout_pred = torch.stack(out).to(device_name)\nprint(calculateAccuracy(out_pred, tensor_hin))","metadata":{"id":"LyHQWp5kI_gP","execution":{"iopub.status.busy":"2023-05-03T20:00:14.812680Z","iopub.execute_input":"2023-05-03T20:00:14.813085Z","iopub.status.idle":"2023-05-03T20:00:17.693346Z","shell.execute_reply.started":"2023-05-03T20:00:14.813050Z","shell.execute_reply":"2023-05-03T20:00:17.692199Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"0.41748046875\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/fdl-a3/hin_test.csv', names=['eng','hin'])\n\neng_words = df_test['eng'].copy()\nfor i in range(len(eng_words)):\n    l = len(eng_words[i])\n    eng_words[i] = eng_words[i] + \"*\"*(24 - l + 3)\nhin_words = df_test['hin'].copy()\nfor i in range(len(hin_words)):\n    l = len(hin_words[i])\n    hin_words[i] = \"#\" + hin_words[i] + \"*\"*(24 - l + 2)\n    \neng_to_int = {v: k for k, v in int_to_eng.items()}\nhin_to_int = {v: k for k, v in int_to_hin.items()}\nhin_to_int['_'] = len(hin_to_int)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7cyXu1OcIx0","outputId":"b6f77907-8198-49c8-eb4e-3946b47637d8","execution":{"iopub.status.busy":"2023-05-03T20:27:20.469637Z","iopub.execute_input":"2023-05-03T20:27:20.470044Z","iopub.status.idle":"2023-05-03T20:27:20.583728Z","shell.execute_reply.started":"2023-05-03T20:27:20.469987Z","shell.execute_reply":"2023-05-03T20:27:20.582754Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"index_eng_words = []\nfor eng_word in eng_words:\n    index_eng_word = [eng_to_int[i] for i in eng_word]\n    index_eng_words.append(index_eng_word)\nindex_hin_words = []\nfor hin_word in hin_words:\n    index_hin_word = [hin_to_int[i] if i in hin_to_int else hin_to_int['_'] for i in hin_word]\n    index_hin_words.append(index_hin_word)\n\ntensor_eng_test = torch.tensor(index_eng_words).to(device_name)\ntensor_hin_test = torch.tensor(index_hin_words).to(device_name)\n\ntrained_pred = eval(tensor_eng_test, tensor_hin_test, encoder, decoder, num_of_enc_layers, num_of_dec_layers, 64, \"GRU\")\n","metadata":{"id":"4kA10NUNLaqR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"21a4d7a9-0f74-4650-c6d5-8877cdef6f92","execution":{"iopub.status.busy":"2023-05-03T20:27:50.006448Z","iopub.execute_input":"2023-05-03T20:27:50.006858Z","iopub.status.idle":"2023-05-03T20:27:51.588990Z","shell.execute_reply.started":"2023-05-03T20:27:50.006826Z","shell.execute_reply":"2023-05-03T20:27:51.588050Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"torch.tensor(trained_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T20:28:18.565053Z","iopub.execute_input":"2023-05-03T20:28:18.566055Z","iopub.status.idle":"2023-05-03T20:28:18.597128Z","shell.execute_reply.started":"2023-05-03T20:28:18.565982Z","shell.execute_reply":"2023-05-03T20:28:18.595912Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"tensor([[[34, 34, 34,  ..., 34, 34, 34],\n         [51, 32,  3,  ...,  3, 25, 63],\n         [37, 11, 10,  ..., 11, 58, 65],\n         ...,\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9]],\n\n        [[34, 34, 34,  ..., 34, 34, 34],\n         [24, 65, 24,  ..., 43, 41, 56],\n         [38, 45,  1,  ..., 52, 38, 11],\n         ...,\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9]],\n\n        [[34, 34, 34,  ..., 34, 34, 34],\n         [ 3, 24, 39,  ..., 43, 21, 63],\n         [14, 65, 38,  ..., 52, 18,  1],\n         ...,\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9]],\n\n        ...,\n\n        [[34, 34, 34,  ..., 34, 34, 34],\n         [44, 37, 43,  ..., 63, 30, 32],\n         [ 2, 57, 11,  ..., 38,  5, 38],\n         ...,\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9]],\n\n        [[34, 34, 34,  ..., 34, 34, 34],\n         [ 3, 63, 17,  ...,  2, 44, 24],\n         [24,  5,  1,  ..., 37, 22, 11],\n         ...,\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9]],\n\n        [[34, 34, 34,  ..., 34, 34, 34],\n         [44, 37, 36,  ..., 30, 41, 17],\n         [41, 35, 63,  ...,  1, 11, 38],\n         ...,\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9],\n         [ 9,  9,  9,  ...,  9,  9,  9]]])"},"metadata":{}}]},{"cell_type":"code","source":"out = []\nten_pred = torch.tensor(trained_pred)\nfor i in range(len(trained_pred)):\n    temp = ten_pred[i].T\n    out.extend(temp)\nout_pred = torch.stack(out).to(device_name)\nprint(calculateAccuracy(out_pred, tensor_hin_test))","metadata":{"id":"WuZjjLpFfAzo","execution":{"iopub.status.busy":"2023-05-03T20:31:59.818713Z","iopub.execute_input":"2023-05-03T20:31:59.819123Z","iopub.status.idle":"2023-05-03T20:32:00.224706Z","shell.execute_reply.started":"2023-05-03T20:31:59.819092Z","shell.execute_reply":"2023-05-03T20:32:00.223641Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"0.323974609375\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0DfQkwvfmDD","outputId":"0218591e-ab57-4db0-ee90-2555c7c6581a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_up[0].shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wlBRhNblgELx","outputId":"a7808a7c-901d-462b-acd6-88121458d5a6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aF2NuCcNDKZc","outputId":"fc9cd517-89f0-4777-c13f-55e85f5488f9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/content/drive/MyDrive/FDL_A3/hin/hin_test.csv', names=['eng','hin'])\neng_words = df_test['eng']\nmaxlen = len(max(df['eng'], key=len))\nindex_eng_words = []\nfor eng_word in eng_words:\n  index_eng_word = [eng_to_int[i] for i in eng_word]\n  l = len(index_eng_word)\n  index_eng_word.extend([0]*(maxlen-l+2))\n  index_eng_words.append(index_eng_word)\n\ntensor_eng_test = torch.tensor(index_eng_words).to(device_name)\ntensor_hin_test = torch.tensor(index_hin_words).to(device_name)","metadata":{"id":"O4N6_to6CIrp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_value = eval(tensor_eng_test, tensor_hin_test, )","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"rBsT_3WzDSg-","outputId":"77a1f39a-8e11-4577-9464-6f94980454cd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Experimental Area**","metadata":{"id":"6h-qHdB__elc"}},{"cell_type":"code","source":"l = [i if i!=5 else 99 for i in range(10)]\nl","metadata":{"id":"YnM5xI7J_uUt","execution":{"iopub.status.busy":"2023-05-03T20:21:05.051096Z","iopub.execute_input":"2023-05-03T20:21:05.051447Z","iopub.status.idle":"2023-05-03T20:21:05.057569Z","shell.execute_reply.started":"2023-05-03T20:21:05.051419Z","shell.execute_reply":"2023-05-03T20:21:05.056668Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"[0, 1, 2, 3, 4, 99, 6, 7, 8, 9]"},"metadata":{}}]},{"cell_type":"code","source":"ten_pred = torch.tensor(trained_pred)\nten_pred[0].T.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-03T20:30:55.460951Z","iopub.execute_input":"2023-05-03T20:30:55.461653Z","iopub.status.idle":"2023-05-03T20:30:55.488862Z","shell.execute_reply.started":"2023-05-03T20:30:55.461619Z","shell.execute_reply":"2023-05-03T20:30:55.487633Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"torch.Size([64, 27])"},"metadata":{}}]},{"cell_type":"code","source":"a = torch.tensor([[[1,2,3],[1,2,3]], [[1,2,3],[1,2,3]]])\nprint(a.shape)\na = a.repeat(2,1,1)\nprint(a.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T21:21:17.317176Z","iopub.execute_input":"2023-05-03T21:21:17.317894Z","iopub.status.idle":"2023-05-03T21:21:17.324969Z","shell.execute_reply.started":"2023-05-03T21:21:17.317857Z","shell.execute_reply":"2023-05-03T21:21:17.324050Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stdout","text":"torch.Size([2, 2, 3])\ntorch.Size([4, 2, 3])\n","output_type":"stream"}]},{"cell_type":"code","source":"out_pred = ten_pred[0].T\nnum=0\nwhile num <10:\n    for i in out_pred[num]:\n        print(int_to_hin[i.item()],end=\"\")\n    print(\"\\n\")\n    num+=1","metadata":{"id":"ic1s-nqVAHFH","execution":{"iopub.status.busy":"2023-05-03T20:31:08.778490Z","iopub.execute_input":"2023-05-03T20:31:08.778893Z","iopub.status.idle":"2023-05-03T20:31:08.789161Z","shell.execute_reply.started":"2023-05-03T20:31:08.778862Z","shell.execute_reply":"2023-05-03T20:31:08.787882Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"#थर्मैक्स******************\n\n#सिखाएगा*******************\n\n#लीयर्न********************\n\n#ट्विटर्स******************\n\n#तिरुनेलवली****************\n\n#इंडेपेंडेंस***************\n\n#स्पेषियों*****************\n\n#शुरूह*********************\n\n#कोल्हापुर*****************\n\n#अझर***********************\n\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in df['eng']:\n  if(len(i) > 24):\n    print(i)","metadata":{"id":"f8o8cuGzAInq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = [1,2,3,4]\na.append(0*4)\na","metadata":{"id":"6OpbtU_mARaD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_up","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_pred = torch(tensor(trained_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcFlF96qnMGL","outputId":"e3b2efca-866d-4306-daa5-d1d08c047626","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in temp[0]:\n    print(int_to_hin[i.item()], end=\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in temp:\n  for j in i:\n    print(int_to_hin[j.item()], end=\"\")\n  print(\"\\n\")","metadata":{"id":"5ZO63eD6IhUu","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"dccff7a9-a466-4bd1-eb75-b8d6283154a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in zip(tensor_eng, tensor_hin):\n  print(x,y)","metadata":{"id":"SUdsTZzTs3P3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(unique_hin_letters)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X4wZuIxvvGHe","outputId":"bdd4e79e-f8a2-48fd-a672-62f1efda3ae7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = [1,2],[3,4]\nb = [1,1],[3,4]\nta = torch.tensor(a)\ntb = torch.tensor(b)\ncalculateAccuracyUPD(a,b)","metadata":{"id":"SK14JJd60Ofz"},"execution_count":null,"outputs":[]}]}